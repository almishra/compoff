['Reduction', 'div_double', 'log_Outer', 'log_Inner', 'log_VarDecl', 'log_refExpr', 'log_intLiteral', 'log_floatLiteral', 'log_mem_to', 'log_mem_from', 'log_add_sub_int', 'log_add_sub_double', 'log_mul_int', 'log_mul_double', 'log_div_int', 'log_div_double', 'log_assign_int', 'log_assign_double', 'runtimes']
2625
19
<class 'numpy.dtype'> float64
2625
train batches:  119  validate samples: 210  test samples: 525
Epoch [0/150], Batch loss: 12.376
Epoch: 0 RMSE:  5.302718207434407  MAPE: 7.610314542323446  L2+L1 loss: 4.851
Epoch [1/150], Batch loss: 3.66
Epoch: 1 RMSE:  4.724644947637402  MAPE: 1.9057228447164123  L2+L1 loss: 3.628
Epoch [2/150], Batch loss: 3.044
Epoch: 2 RMSE:  4.002046097409187  MAPE: 2.0111150843228485  L2+L1 loss: 3.24
Epoch [3/150], Batch loss: 3.244
Epoch: 3 RMSE:  2.064546302166471  MAPE: 1.9829133660488538  L2+L1 loss: 2.098
Epoch [4/150], Batch loss: 3.246
Epoch: 4 RMSE:  3.0589348484467442  MAPE: 2.398313835808689  L2+L1 loss: 2.715
Epoch [5/150], Batch loss: 2.668
Epoch: 5 RMSE:  5.7287927871741955  MAPE: 1.416385277984391  L2+L1 loss: 3.124
Epoch [6/150], Batch loss: 3.292
Epoch: 6 RMSE:  3.523131316059148  MAPE: 1.9261129144510667  L2+L1 loss: 2.497
Epoch [7/150], Batch loss: 5.54
Epoch: 7 RMSE:  5.092138628468639  MAPE: 5.849740478205924  L2+L1 loss: 4.699
Epoch [8/150], Batch loss: 5.695
Epoch: 8 RMSE:  5.097356885280491  MAPE: 5.982655235868397  L2+L1 loss: 4.733
Epoch [9/150], Batch loss: 5.764
Epoch: 9 RMSE:  5.089358365356399  MAPE: 5.699295479480457  L2+L1 loss: 4.662
Epoch [10/150], Batch loss: 5.686
Epoch: 10 RMSE:  7.572315333948567  MAPE: 12.381879054440708  L2+L1 loss: 5.041
Epoch [11/150], Batch loss: 6.775
Epoch: 11 RMSE:  7.109871465980856  MAPE: 11.308785170232042  L2+L1 loss: 5.747
Epoch [12/150], Batch loss: 6.623
Epoch: 12 RMSE:  4.747702194317529  MAPE: 5.553881743034729  L2+L1 loss: 4.434
Epoch [13/150], Batch loss: 4.713
Epoch: 13 RMSE:  2.8889592309286756  MAPE: 2.630853668096955  L2+L1 loss: 2.423
Epoch [14/150], Batch loss: 4.121
Epoch: 14 RMSE:  2.9474031418471016  MAPE: 2.0099522402030225  L2+L1 loss: 2.538
Epoch [15/150], Batch loss: 5.678
Epoch: 15 RMSE:  4.9866467543647595  MAPE: 5.6542766015795785  L2+L1 loss: 4.545
Epoch [16/150], Batch loss: 4.211
Epoch: 16 RMSE:  2.9984868603324926  MAPE: 2.4220685464473863  L2+L1 loss: 2.583
Epoch [17/150], Batch loss: 5.277
Epoch: 17 RMSE:  5.476764219737096  MAPE: 3.3555152527288197  L2+L1 loss: 4.212
Epoch [18/150], Batch loss: 5.776
Epoch: 18 RMSE:  5.10326647346365  MAPE: 6.087193430354317  L2+L1 loss: 4.761
Epoch [19/150], Batch loss: 5.828
Epoch: 19 RMSE:  5.089996444895593  MAPE: 5.754836271984682  L2+L1 loss: 4.676
Epoch [20/150], Batch loss: 5.767
Epoch: 20 RMSE:  5.0893133853979275  MAPE: 5.6054861693531235  L2+L1 loss: 4.638
Epoch [21/150], Batch loss: 5.746
Epoch: 21 RMSE:  5.089631940436672  MAPE: 5.72804957574253  L2+L1 loss: 4.669
Epoch [22/150], Batch loss: 5.769
Epoch: 22 RMSE:  5.089723321582702  MAPE: 5.56272907317309  L2+L1 loss: 4.627
Epoch [23/150], Batch loss: 5.783
Epoch: 23 RMSE:  5.094602810894381  MAPE: 5.920631175681839  L2+L1 loss: 4.716
Epoch [24/150], Batch loss: 6.085
Epoch: 24 RMSE:  5.147466908214469  MAPE: 4.76146549781463  L2+L1 loss: 4.442
Epoch [25/150], Batch loss: 5.704
Epoch: 25 RMSE:  5.096073323514979  MAPE: 5.955299297004777  L2+L1 loss: 4.725
Epoch [26/150], Batch loss: 5.758
Epoch: 26 RMSE:  5.0893105716383245  MAPE: 5.692351779466104  L2+L1 loss: 4.66
Epoch [27/150], Batch loss: 5.725
Epoch: 27 RMSE:  5.089382896678296  MAPE: 5.595767521521077  L2+L1 loss: 4.636
Epoch [28/150], Batch loss: 5.82
Epoch: 28 RMSE:  5.08926789256883  MAPE: 5.613244022873204  L2+L1 loss: 4.64
Epoch [29/150], Batch loss: 5.748
Epoch: 29 RMSE:  5.094927292215497  MAPE: 5.369756578839302  L2+L1 loss: 4.577
Epoch [30/150], Batch loss: 5.709
Epoch: 30 RMSE:  5.090428631131669  MAPE: 5.518617806861828  L2+L1 loss: 4.616
Epoch [31/150], Batch loss: 5.759
Epoch: 31 RMSE:  5.089172940358421  MAPE: 5.648500888143488  L2+L1 loss: 4.649
Epoch [32/150], Batch loss: 5.71
Epoch: 32 RMSE:  5.0891756121004255  MAPE: 5.655192470304142  L2+L1 loss: 4.651
Epoch [33/150], Batch loss: 5.799
Epoch: 33 RMSE:  5.089527193376915  MAPE: 5.718463592545293  L2+L1 loss: 4.666
Epoch [34/150], Batch loss: 5.718
Epoch: 34 RMSE:  5.089634049776561  MAPE: 5.728230682235692  L2+L1 loss: 4.669
Epoch [35/150], Batch loss: 5.777
Epoch: 35 RMSE:  5.089977530328317  MAPE: 5.753615316963924  L2+L1 loss: 4.675
Epoch [36/150], Batch loss: 5.755
Epoch: 36 RMSE:  5.085428016344026  MAPE: 5.781300524648848  L2+L1 loss: 4.669
Epoch [37/150], Batch loss: 5.85
Epoch: 37 RMSE:  5.0897838667032405  MAPE: 5.740177105076307  L2+L1 loss: 4.672
Epoch [38/150], Batch loss: 5.734
Epoch: 38 RMSE:  5.0897245127550645  MAPE: 5.735641736088018  L2+L1 loss: 4.671
Epoch [39/150], Batch loss: 5.788
Epoch: 39 RMSE:  5.089707385523167  MAPE: 5.734288116432454  L2+L1 loss: 4.67
Epoch [40/150], Batch loss: 6.065
Epoch: 40 RMSE:  5.089411911231534  MAPE: 5.706077890125523  L2+L1 loss: 4.663
Epoch [41/150], Batch loss: 5.558
Epoch: 41 RMSE:  2.877760311791069  MAPE: 2.643804384924189  L2+L1 loss: 2.048
Epoch [42/150], Batch loss: 4.858
Epoch: 42 RMSE:  4.049692106305343  MAPE: 2.255048025394945  L2+L1 loss: 2.937
Epoch [43/150], Batch loss: 4.578
Epoch: 43 RMSE:  3.596568205590933  MAPE: 1.2554591553665997  L2+L1 loss: 2.396
Epoch [44/150], Batch loss: 4.204
Epoch: 44 RMSE:  3.7096493800951333  MAPE: 3.163656363989371  L2+L1 loss: 3.277
Epoch [45/150], Batch loss: 3.855
Epoch: 45 RMSE:  3.0535757689628857  MAPE: 1.5681768667693876  L2+L1 loss: 1.894
Epoch [46/150], Batch loss: 3.614
Epoch: 46 RMSE:  2.805230909705135  MAPE: 1.623840517683794  L2+L1 loss: 1.773
Epoch [47/150], Batch loss: 3.498
Epoch: 47 RMSE:  1.503875766536946  MAPE: 1.1336140929614906  L2+L1 loss: 1.423
Epoch [48/150], Batch loss: 3.112
Epoch: 48 RMSE:  1.900767150286754  MAPE: 2.1435540171513052  L2+L1 loss: 1.641
Epoch [49/150], Batch loss: 3.307
Epoch: 49 RMSE:  2.5333377395286467  MAPE: 1.8161176057439985  L2+L1 loss: 1.878
Epoch [50/150], Batch loss: 3.049
Epoch: 50 RMSE:  2.2277731795808684  MAPE: 1.1029940330767443  L2+L1 loss: 1.858
Epoch [51/150], Batch loss: 2.911
Epoch: 51 RMSE:  2.0694876331332606  MAPE: 1.451607934263609  L2+L1 loss: 1.372
Epoch [52/150], Batch loss: 2.681
Epoch: 52 RMSE:  1.7913724585427515  MAPE: 0.7351204384363219  L2+L1 loss: 1.124
Epoch [53/150], Batch loss: 2.511
Epoch: 53 RMSE:  1.8965402150965436  MAPE: 1.963174486466147  L2+L1 loss: 1.553
Epoch [54/150], Batch loss: 2.47
Epoch: 54 RMSE:  1.5564290094584974  MAPE: 0.5750218914616959  L2+L1 loss: 1.314
Epoch [55/150], Batch loss: 2.083
Epoch: 55 RMSE:  1.02620166406767  MAPE: 0.7220089742893767  L2+L1 loss: 0.89
Epoch [56/150], Batch loss: 1.464
Epoch: 56 RMSE:  2.0141350262238333  MAPE: 2.2582968113240547  L2+L1 loss: 1.361
Epoch [57/150], Batch loss: 1.342
Epoch: 57 RMSE:  1.1850357215597602  MAPE: 0.8732387260471844  L2+L1 loss: 0.983
Epoch [58/150], Batch loss: 1.11
Epoch: 58 RMSE:  0.671137021705453  MAPE: 0.7239200440710517  L2+L1 loss: 0.855
Epoch [59/150], Batch loss: 2.445
Epoch: 59 RMSE:  3.1707050115659956  MAPE: 3.596320801992387  L2+L1 loss: 2.248
Epoch [60/150], Batch loss: 1.938
Epoch: 60 RMSE:  1.4003711669231127  MAPE: 0.4853152842423979  L2+L1 loss: 0.958
Epoch [61/150], Batch loss: 1.339
Epoch: 61 RMSE:  1.3350323091339922  MAPE: 0.3272190741613202  L2+L1 loss: 0.892
Epoch [62/150], Batch loss: 1.305
Epoch: 62 RMSE:  1.299421633642185  MAPE: 0.4345070531495013  L2+L1 loss: 0.853
Epoch [63/150], Batch loss: 1.386
Epoch: 63 RMSE:  1.275824614049191  MAPE: 0.3709468703320296  L2+L1 loss: 0.87
Epoch [64/150], Batch loss: 1.22
Epoch: 64 RMSE:  1.264768471057304  MAPE: 0.3816498523312157  L2+L1 loss: 0.933
Epoch [65/150], Batch loss: 1.246
Epoch: 65 RMSE:  1.2273650528009739  MAPE: 0.409811109896694  L2+L1 loss: 0.811
Epoch [66/150], Batch loss: 1.295
Epoch: 66 RMSE:  1.2278339081554925  MAPE: 0.6382464751979708  L2+L1 loss: 0.856
Epoch [67/150], Batch loss: 0.866
Epoch: 67 RMSE:  0.6371040675225189  MAPE: 0.4749913369114952  L2+L1 loss: 0.597
Epoch [68/150], Batch loss: 0.636
Epoch: 68 RMSE:  0.6676528852999621  MAPE: 0.29815687791650913  L2+L1 loss: 0.613
Epoch [69/150], Batch loss: 0.789
Epoch: 69 RMSE:  0.6233941242565022  MAPE: 0.3731192843284752  L2+L1 loss: 0.604
Epoch [70/150], Batch loss: 0.455
Epoch: 70 RMSE:  0.5693670032926987  MAPE: 0.5480452561637661  L2+L1 loss: 0.74
Epoch [71/150], Batch loss: 0.455
Epoch: 71 RMSE:  0.5396292022597546  MAPE: 0.6046944691073032  L2+L1 loss: 0.685
Epoch [72/150], Batch loss: 0.46
Epoch: 72 RMSE:  0.6120780913849733  MAPE: 0.538548629757678  L2+L1 loss: 0.695
Epoch [73/150], Batch loss: 0.616
Epoch: 73 RMSE:  0.5321985782248283  MAPE: 0.5449548638769716  L2+L1 loss: 0.725
Epoch [74/150], Batch loss: 0.597
Epoch: 74 RMSE:  0.43376321667920653  MAPE: 0.1882322336022435  L2+L1 loss: 0.476
Epoch [75/150], Batch loss: 0.387
Epoch: 75 RMSE:  0.4117124073169086  MAPE: 0.26234189775110517  L2+L1 loss: 0.463
Epoch [76/150], Batch loss: 0.595
Epoch: 76 RMSE:  0.6393761692672391  MAPE: 0.6302104644654644  L2+L1 loss: 0.889
Epoch [77/150], Batch loss: 0.466
Epoch: 77 RMSE:  0.46452903562225195  MAPE: 0.2370008409662377  L2+L1 loss: 0.606
Epoch [78/150], Batch loss: 0.597
Epoch: 78 RMSE:  0.4373100605482173  MAPE: 0.33600144490833844  L2+L1 loss: 0.612
Epoch [79/150], Batch loss: 0.49
Epoch: 79 RMSE:  0.37355285615715705  MAPE: 0.23773456523398506  L2+L1 loss: 0.451
Epoch [80/150], Batch loss: 0.428
Epoch: 80 RMSE:  0.47564552938102245  MAPE: 0.26715595898621564  L2+L1 loss: 0.597
Epoch [81/150], Batch loss: 0.708
Epoch: 81 RMSE:  0.38998423093088014  MAPE: 0.31690847287031043  L2+L1 loss: 0.504
Epoch [82/150], Batch loss: 0.344
Epoch: 82 RMSE:  0.5767042407288124  MAPE: 0.628222167744523  L2+L1 loss: 0.701
Epoch [83/150], Batch loss: 0.547
Epoch: 83 RMSE:  0.3581170008449598  MAPE: 0.1510843029820403  L2+L1 loss: 0.414
Epoch [84/150], Batch loss: 0.324
Epoch: 84 RMSE:  0.36409062433411205  MAPE: 0.1934853801589475  L2+L1 loss: 0.468
Epoch [85/150], Batch loss: 0.408
Epoch: 85 RMSE:  0.646114231544817  MAPE: 0.6071908119812838  L2+L1 loss: 0.758
Epoch [86/150], Batch loss: 0.425
Epoch: 86 RMSE:  0.40600887743913155  MAPE: 0.2568538708557833  L2+L1 loss: 0.491
Epoch [87/150], Batch loss: 0.267
Epoch: 87 RMSE:  0.3490611907013872  MAPE: 0.15925380779870119  L2+L1 loss: 0.431
Epoch [88/150], Batch loss: 0.287
Epoch: 88 RMSE:  0.3378203701078993  MAPE: 0.23569647716867648  L2+L1 loss: 0.431
Epoch [89/150], Batch loss: 0.369
Epoch: 89 RMSE:  0.7100508336974181  MAPE: 0.7561972536598258  L2+L1 loss: 0.929
Epoch [90/150], Batch loss: 0.682
Epoch: 90 RMSE:  0.3304665907362775  MAPE: 0.15158415949547424  L2+L1 loss: 0.383
Epoch [91/150], Batch loss: 0.282
Epoch: 91 RMSE:  0.33552416206013547  MAPE: 0.2587713862532014  L2+L1 loss: 0.439
Epoch [92/150], Batch loss: 0.209
Epoch: 92 RMSE:  0.3251365651167569  MAPE: 0.20609481989071307  L2+L1 loss: 0.379
Epoch [93/150], Batch loss: 0.202
Epoch: 93 RMSE:  0.32381481743420676  MAPE: 0.19578939439913506  L2+L1 loss: 0.375
Epoch [94/150], Batch loss: 0.198
Epoch: 94 RMSE:  0.32142132168837634  MAPE: 0.17065186290826234  L2+L1 loss: 0.384
Epoch [95/150], Batch loss: 0.199
Epoch: 95 RMSE:  0.3192117715318063  MAPE: 0.1757069715163879  L2+L1 loss: 0.376
Epoch [96/150], Batch loss: 0.205
Epoch: 96 RMSE:  0.31882728369340957  MAPE: 0.1542396209252548  L2+L1 loss: 0.372
Epoch [97/150], Batch loss: 0.205
Epoch: 97 RMSE:  0.3188952939183062  MAPE: 0.1537120142876772  L2+L1 loss: 0.379
Epoch [98/150], Batch loss: 0.203
Epoch: 98 RMSE:  0.3274798833403883  MAPE: 0.26713090480214086  L2+L1 loss: 0.422
Epoch [99/150], Batch loss: 0.197
Epoch: 99 RMSE:  0.31037210982004854  MAPE: 0.1841494330073657  L2+L1 loss: 0.369
Epoch [100/150], Batch loss: 0.197
Epoch: 100 RMSE:  0.3091444688290944  MAPE: 0.14389897510325372  L2+L1 loss: 0.368
Epoch [101/150], Batch loss: 0.199
Epoch: 101 RMSE:  0.3360937917518847  MAPE: 0.33286669361098487  L2+L1 loss: 0.483
Epoch [102/150], Batch loss: 0.201
Epoch: 102 RMSE:  0.3102301616477984  MAPE: 0.13669206249220875  L2+L1 loss: 0.371
Epoch [103/150], Batch loss: 0.198
Epoch: 103 RMSE:  0.31401725628711896  MAPE: 0.24840649718410693  L2+L1 loss: 0.42
Epoch [104/150], Batch loss: 0.203
Epoch: 104 RMSE:  0.30188851396957794  MAPE: 0.1599026620741182  L2+L1 loss: 0.369
Epoch [105/150], Batch loss: 0.188
Epoch: 105 RMSE:  0.3004145968575025  MAPE: 0.17035912142796686  L2+L1 loss: 0.378
Epoch [106/150], Batch loss: 0.194
Epoch: 106 RMSE:  0.29902608407257886  MAPE: 0.16555308180734213  L2+L1 loss: 0.364
Epoch [107/150], Batch loss: 0.196
Epoch: 107 RMSE:  0.29995926127093586  MAPE: 0.18441778760113803  L2+L1 loss: 0.373
Epoch [108/150], Batch loss: 0.21
Epoch: 108 RMSE:  0.296714685531572  MAPE: 0.19675280926877942  L2+L1 loss: 0.368
Epoch [109/150], Batch loss: 0.186
Epoch: 109 RMSE:  0.29487112937555915  MAPE: 0.1792496922305319  L2+L1 loss: 0.374
Epoch [110/150], Batch loss: 0.187
Epoch: 110 RMSE:  0.30897896056360835  MAPE: 0.12904769116526527  L2+L1 loss: 0.385
Epoch [111/150], Batch loss: 0.207
Epoch: 111 RMSE:  0.2926799557366217  MAPE: 0.19383456343915137  L2+L1 loss: 0.384
Epoch [112/150], Batch loss: 0.186
Epoch: 112 RMSE:  0.30306018579702015  MAPE: 0.26911234407232165  L2+L1 loss: 0.419
Epoch [113/150], Batch loss: 0.177
Epoch: 113 RMSE:  0.2929972120978235  MAPE: 0.12175016752116093  L2+L1 loss: 0.363
Epoch [114/150], Batch loss: 0.196
Epoch: 114 RMSE:  0.2928794614395688  MAPE: 0.21176365630986763  L2+L1 loss: 0.364
Epoch [115/150], Batch loss: 0.189
Epoch: 115 RMSE:  0.31715105363084645  MAPE: 0.1954439757709235  L2+L1 loss: 0.414
Epoch [116/150], Batch loss: 0.194
Epoch: 116 RMSE:  0.28453008950385567  MAPE: 0.13952687585636536  L2+L1 loss: 0.357
Epoch [117/150], Batch loss: 0.183
Epoch: 117 RMSE:  0.2860054348334604  MAPE: 0.14138924372665151  L2+L1 loss: 0.355
Epoch [118/150], Batch loss: 0.185
Epoch: 118 RMSE:  0.291470802551252  MAPE: 0.1754025045455274  L2+L1 loss: 0.395
Epoch [119/150], Batch loss: 0.185
Epoch: 119 RMSE:  0.28375534320692786  MAPE: 0.11934190992806627  L2+L1 loss: 0.349
Epoch [120/150], Batch loss: 0.17
Epoch: 120 RMSE:  0.2814172131007772  MAPE: 0.14214415162329483  L2+L1 loss: 0.352
Epoch [121/150], Batch loss: 0.165
Epoch: 121 RMSE:  0.2810486709793747  MAPE: 0.1427513526318058  L2+L1 loss: 0.352
Epoch [122/150], Batch loss: 0.166
Epoch: 122 RMSE:  0.28080175573847616  MAPE: 0.14494346668130476  L2+L1 loss: 0.352
Epoch [123/150], Batch loss: 0.164
Epoch: 123 RMSE:  0.280302518764907  MAPE: 0.14910705105947014  L2+L1 loss: 0.35
Epoch [124/150], Batch loss: 0.17
Epoch: 124 RMSE:  0.2800333467952531  MAPE: 0.15392415943971713  L2+L1 loss: 0.357
Epoch [125/150], Batch loss: 0.168
Epoch: 125 RMSE:  0.2799540184712027  MAPE: 0.1455149285770082  L2+L1 loss: 0.348
Epoch [126/150], Batch loss: 0.17
Epoch: 126 RMSE:  0.28024384427463894  MAPE: 0.1443336387189716  L2+L1 loss: 0.349
Epoch [127/150], Batch loss: 0.168
Epoch: 127 RMSE:  0.2793537101141071  MAPE: 0.14607177571782867  L2+L1 loss: 0.349
Epoch [128/150], Batch loss: 0.166
Epoch: 128 RMSE:  0.2792583679436663  MAPE: 0.15169101200390486  L2+L1 loss: 0.35
Epoch [129/150], Batch loss: 0.168
Epoch: 129 RMSE:  0.27897648576164186  MAPE: 0.15377348588222603  L2+L1 loss: 0.352
Epoch [130/150], Batch loss: 0.167
Epoch: 130 RMSE:  0.27889120135824924  MAPE: 0.14547253988023776  L2+L1 loss: 0.348
Epoch [131/150], Batch loss: 0.167
Epoch: 131 RMSE:  0.27864078506717427  MAPE: 0.1573321391780649  L2+L1 loss: 0.355
Epoch [132/150], Batch loss: 0.169
Epoch: 132 RMSE:  0.27877799612689436  MAPE: 0.14661950433384935  L2+L1 loss: 0.348
Epoch [133/150], Batch loss: 0.168
Epoch: 133 RMSE:  0.2784981713436297  MAPE: 0.14850208888247865  L2+L1 loss: 0.349
Epoch [134/150], Batch loss: 0.169
Epoch: 134 RMSE:  0.2780443581345436  MAPE: 0.15672672755374145  L2+L1 loss: 0.356
Epoch [135/150], Batch loss: 0.169
Epoch: 135 RMSE:  0.2777500808293136  MAPE: 0.15182126409547578  L2+L1 loss: 0.355
Epoch [136/150], Batch loss: 0.166
Epoch: 136 RMSE:  0.2778291206606438  MAPE: 0.13978320143303938  L2+L1 loss: 0.347
Epoch [137/150], Batch loss: 0.167
Epoch: 137 RMSE:  0.2774373087413995  MAPE: 0.15292490796512329  L2+L1 loss: 0.354
Epoch [138/150], Batch loss: 0.167
Epoch: 138 RMSE:  0.2772926934440917  MAPE: 0.15614048418289606  L2+L1 loss: 0.354
Epoch [139/150], Batch loss: 0.167
Epoch: 139 RMSE:  0.27714794940540943  MAPE: 0.14378902528544357  L2+L1 loss: 0.348
Epoch [140/150], Batch loss: 0.164
Epoch: 140 RMSE:  0.27683572541896107  MAPE: 0.1535815378760419  L2+L1 loss: 0.354
Epoch [141/150], Batch loss: 0.168
Epoch: 141 RMSE:  0.2793827954873235  MAPE: 0.17313412436440198  L2+L1 loss: 0.371
Epoch [142/150], Batch loss: 0.167
Epoch: 142 RMSE:  0.2768123196607889  MAPE: 0.15313366469222556  L2+L1 loss: 0.356
Epoch [143/150], Batch loss: 0.166
Epoch: 143 RMSE:  0.27776128945207107  MAPE: 0.1356341220378852  L2+L1 loss: 0.347
Epoch [144/150], Batch loss: 0.166
Epoch: 144 RMSE:  0.2761855679918688  MAPE: 0.1523890639862635  L2+L1 loss: 0.356
Epoch [145/150], Batch loss: 0.165
Epoch: 145 RMSE:  0.2761782358410805  MAPE: 0.15196082156071639  L2+L1 loss: 0.35
Epoch [146/150], Batch loss: 0.167
Epoch: 146 RMSE:  0.27602453775433305  MAPE: 0.154807242761661  L2+L1 loss: 0.353
Epoch [147/150], Batch loss: 0.166
Epoch: 147 RMSE:  0.2757375880469199  MAPE: 0.15295716087628214  L2+L1 loss: 0.356
Epoch [148/150], Batch loss: 0.164
Epoch: 148 RMSE:  0.2757909397959395  MAPE: 0.14084481654318196  L2+L1 loss: 0.347
Epoch [149/150], Batch loss: 0.167
Epoch: 149 RMSE:  0.27539184185953014  MAPE: 0.15386613178552538  L2+L1 loss: 0.358


Evaluating Model.......
Best Model - RMSE: inf  MAPE: inf  L2+L1- inf
predicted_runtime, ground_truth
14.325198 , 14.2633
1.068903 , 1.3971
7.0890474 , 7.1568
8.809645 , 8.6689
2.65106 , 2.6025
0.5635805 , 0.4817
1.8831596 , 1.9102
5.8078456 , 5.9972
6.4995837 , 6.4987
19.116253 , 18.8561
2.1306648 , 2.1105
1.4667892 , 1.089315
2.4283094 , 2.3517
1.8043165 , 1.8595
1.7433968 , 2.533997
11.014631 , 11.2754
2.2796488 , 2.249
3.6474028 , 3.4989
3.5703297 , 3.2778
12.056099 , 12.0063
0.3973446 , 0.4622
2.2373695 , 2.1851
0.34551048 , 0.2135
0.45971394 , 0.4063
0.34484673 , 0.4714
15.171139 , 14.8753
4.986183 , 4.8701
7.5978823 , 7.6863
3.6293278 , 3.605
0.44341087 , 0.5003
5.564241 , 5.3821
65.571976 , 66.7647
1.9615383 , 1.9373
0.19398117 , 0.2242
0.38224316 , 0.3503
16.169737 , 16.6749
9.591546 , 9.5722
1.1850796 , 1.04
2.4991026 , 2.4676
8.557155 , 8.001
3.399826 , 3.36
4.3680973 , 4.4139
8.970162 , 8.7635
0.31729603 , 0.3128
0.59374046 , 0.4581
9.3317375 , 9.3063
5.149707 , 5.2598
0.3357296 , 0.3187
6.7428827 , 6.4311
7.380925 , 7.3156
7.2679825 , 7.2041
0.21442223 , 0.1087
3.112897 , 3.0757
0.25693607 , 0.1795
2.3121014 , 2.2995
5.9957037 , 6.0267
5.5830007 , 5.6721
0.40663052 , 0.2293
4.74922 , 4.7005
2.162448 , 2.2023
7.2703314 , 7.3595
0.3300743 , 0.4269
0.46982193 , 0.4016
5.287614 , 5.349
5.3992796 , 5.3708
3.3305721 , 3.2604
4.151903 , 4.187
2.0459976 , 2.0152
3.7944822 , 3.6904
5.079626 , 4.9635
18.733976 , 18.5574
0.11149502 , 0.1732
10.744445 , 10.5648
11.635393 , 11.7137
72.12598 , 72.2133
0.37622452 , 0.3653
1.1120033 , 0.9697
3.7665462 , 3.6006
19.364605 , 19.1867
0.16831589 , 0.1717
2.1775637 , 2.1386
2.4400158 , 2.3931
0.42120743 , 0.132
3.4691648 , 3.5503
2.1301432 , 2.1179
1.4489117 , 1.1793
0.3155775 , 0.3093
0.5362625 , 0.4995
3.0139618 , 2.9224
11.788544 , 12.3634
0.21897984 , 0.2614
0.47702122 , 0.2981
3.1657877 , 3.1716
2.0408278 , 1.9349
2.111988 , 2.0803
10.25585 , 10.1895
76.755585 , 76.9536
1.9118814 , 1.9265
0.49137878 , 0.6473
6.429579 , 6.3254
82.70375 , 82.197
4.298562 , 4.6053
4.8628807 , 4.8782
0.42800617 , 0.1282
16.411743 , 16.297
3.4885092 , 3.4007
0.2390871 , 0.1853
11.907048 , 12.0217
0.8852482 , 1.0413
3.9882622 , 4.0622
16.257881 , 16.5579
15.259247 , 15.0504
12.9469385 , 13.014
8.369831 , 8.7578
0.6996546 , 0.7727
18.691877 , 18.3514
0.34174728 , 0.2627
0.33995533 , 0.2711
4.4787455 , 4.6158
11.909204 , 12.0016
3.217844 , 3.2241
2.1324558 , 2.0408
22.395819 , 22.4092
3.1179771 , 3.0181
12.652433 , 12.8454
0.4620018 , 0.5177
0.16486931 , 0.1219
0.51008797 , 0.6421
3.5473442 , 3.2932
13.833753 , 13.8307
6.8590875 , 6.4525
3.1765728 , 3.105
2.3052769 , 2.3372
0.2572422 , 0.2255
2.837864 , 2.8247
12.109225 , 11.9973
3.2998943 , 3.577
4.7152643 , 4.7574
4.447654 , 4.4029
12.3715725 , 12.7157
12.157506 , 11.6735
2.1653976 , 2.194
10.2227955 , 10.0263
2.3692703 , 2.3085
1.2267838 , 1.0308
0.10803223 , 0.1454
16.87111 , 16.8008
2.8607874 , 2.7536
7.7347755 , 7.767
2.7550116 , 2.7002
11.117281 , 11.129
2.0420723 , 2.0056
2.9842596 , 2.8896
7.541859 , 7.2013
2.0952892 , 2.0954
0.6088352 , 0.5994
13.214692 , 13.0347
3.3231468 , 3.2979
3.193945 , 3.1689
7.805127 , 7.652
0.50352573 , 0.5988
0.15037918 , 0.1779
2.0342426 , 2.0178
2.5531044 , 2.4298
1.1662292 , 1.0299
3.3678074 , 3.426
3.5182114 , 3.5142
4.343322 , 4.1434
2.8406 , 2.773
0.46375751 , 0.4143
2.316557 , 2.2881
1.741108 , 1.404995
0.09511089 , 0.1531
7.2406883 , 7.1728
1.9304056 , 2.0083
0.19471169 , 0.1145
2.6461182 , 2.6421
1.9314804 , 1.8435
1.4443874 , 1.2574
2.5876198 , 2.5151
5.704649 , 5.6311
18.126993 , 17.9766
2.0857315 , 1.9527
14.806748 , 15.2126
2.700117 , 2.7143
9.656468 , 9.5594
19.347212 , 19.6751
1.7569809 , 1.7748
0.70705414 , 0.8105
5.016796 , 4.7961
0.3168707 , 0.2869
0.357625 , 0.3448
2.1926622 , 2.2324
8.236899 , 8.0665
5.91129 , 6.16
2.6072493 , 2.5442
1.0732765 , 1.0457
2.378107 , 2.2915
6.4331026 , 6.1699
11.115141 , 11.2926
9.168849 , 9.3622
2.3807259 , 2.5182
0.6199684 , 0.8026
9.587402 , 9.5842
7.724513 , 7.9322
0.43874168 , 0.3482
13.280381 , 13.2171
3.4667702 , 3.2769
2.9529562 , 2.9445
11.13681 , 11.2442
0.23179054 , 0.1792
14.472457 , 14.4087
0.42179108 , 0.3452
0.3678074 , 0.3205
1.9157219 , 1.9473
0.4036131 , 0.3472
12.6177845 , 12.8108
19.476114 , 19.3566
1.895771 , 2.0522
2.4443674 , 2.4159
6.0822396 , 5.7605
3.3741665 , 3.2526
9.909646 , 9.9406
3.117547 , 3.1342
11.884629 , 11.9418
3.1747723 , 3.055
10.193841 , 10.4208
14.400114 , 14.1976
9.817272 , 9.6491
2.702444 , 2.6444
11.0153265 , 11.1461
0.559 , 0.533
0.66780186 , 0.6049
1.8688984 , 2.0427
1.8970251 , 1.9848
4.9132223 , 4.8473
10.112841 , 10.1899
2.9337368 , 2.8842
2.931057 , 2.9012
0.14460945 , 0.1466
0.61974907 , 0.5834
0.23950863 , 0.2055
3.3302383 , 3.3207
7.571415 , 7.2637
3.2666378 , 3.2937
2.0974627 , 2.0816
0.22505283 , 0.2381
0.7303791 , 0.828
6.012967 , 6.1477
16.809116 , 15.6564
13.069063 , 12.0225
16.868584 , 16.796
2.0729523 , 2.1053
3.301237 , 3.3713
0.0671711 , 0.1993
11.07381 , 11.2209
5.4829216 , 5.4978
6.6312017 , 6.5426
0.1887331 , 0.2314
2.5487003 , 2.4098
1.10705 , 1.3085
7.570698 , 7.4027
0.5883856 , 0.6968
1.0712242 , 1.1655
19.41027 , 18.8179
0.32461834 , 0.3428
8.721504 , 8.6904
13.847365 , 13.716
6.4846706 , 6.4319
0.918067 , 0.8109
10.145542 , 9.9944
2.2074509 , 2.2233
3.6630316 , 3.5662
6.045818 , 6.0156
3.0539598 , 2.9949
1.8951883 , 1.9124
0.2406025 , 0.1167
4.9955606 , 4.8946
0.33817482 , 0.2887
13.51521 , 12.9916
7.64135 , 7.5636
5.354658 , 5.3144
0.05727005 , 0.1185
0.6112299 , 0.6842
2.3622456 , 2.3334
4.815399 , 4.7909
2.4589806 , 2.359
1.8337173 , 1.8859
1.8091049 , 1.7636
2.4456768 , 2.6504
9.711006 , 9.5679
0.090927124 , 0.1528
2.3511038 , 2.4997
8.682291 , 8.6158
0.20260811 , 0.1184
0.22214985 , 0.4195
0.17513943 , 0.1797
19.479027 , 19.585
5.9986086 , 6.1204
16.633629 , 16.5788
2.5048647 , 2.4129
0.23693275 , 0.2348
15.683696 , 15.8038
2.778901 , 2.7216
4.005555 , 4.8904
2.8601341 , 2.7984
2.9298391 , 2.8687
2.3210068 , 2.2995
8.896144 , 8.8027
2.0419502 , 2.0461
6.272811 , 6.323
0.40459442 , 0.4301
2.1721268 , 2.0948
3.0174503 , 2.943
8.787744 , 8.7608
3.3854294 , 3.2721
8.9064245 , 8.9768
5.89935 , 5.8069
11.083168 , 11.1207
3.338047 , 3.3749
6.453558 , 6.6131
0.55844593 , 0.5126
2.527813 , 2.4835
3.4566183 , 3.25
3.104783 , 3.0396
0.37459946 , 0.3985
7.6044655 , 7.1646
2.4500322 , 2.3629
2.9539566 , 2.8874
2.0762863 , 2.0701
18.458508 , 21.0932
16.9155 , 16.624
0.22563839 , 0.2182
10.50379 , 10.4821
2.719697 , 2.6679
3.2820263 , 3.25
15.764696 , 16.1145
11.186594 , 11.0764
1.1166725 , 0.368378
2.1522474 , 2.088
13.229281 , 13.4611
10.479317 , 10.5246
2.3548813 , 2.3165
0.39980793 , 0.6149
8.89108 , 8.8703
17.915096 , 17.8675
2.9715748 , 2.9768
0.059387207 , 0.1368
1.9504776 , 1.8504
11.957952 , 11.6834
11.85017 , 11.8969
4.394308 , 4.2712
7.885577 , 7.5719
11.552044 , 11.6436
14.396066 , 14.3062
14.424368 , 14.3486
11.959977 , 11.9369
0.19184208 , 0.2389
6.7298994 , 6.5728
2.5283136 , 2.4189
4.1813936 , 4.2278
2.792799 , 2.8012
4.739092 , 4.1547
2.8600855 , 2.7775
8.065977 , 7.7377
1.1585674 , 1.0245
21.054913 , 21.1228
3.61446 , 3.5378
15.887814 , 16.0782
0.40650177 , 0.324
2.4047146 , 2.3949
0.26277637 , 0.2043
0.2737751 , 0.171
0.6032734 , 0.5202
3.1747513 , 3.1028
0.20598984 , 0.1464
1.29352 , 1.0355
0.7607527 , 0.8035
0.31176662 , 0.2577
2.307951 , 2.3382
2.6973019 , 2.5877
3.4325476 , 4.0275
7.634675 , 7.7889
11.342221 , 11.2815
5.2305355 , 4.9717
2.914054 , 2.8323
0.1334877 , 0.1621
9.416744 , 9.2199
8.229008 , 7.9479
0.32932377 , 0.3042
1.0276108 , 1.3308
4.3385887 , 4.3033
0.21706009 , 0.3033
9.693293 , 9.9765
4.56707 , 4.4024
2.2516222 , 2.1661
22.081957 , 21.7007
2.9673462 , 2.8669
2.6793165 , 2.6826
3.3655624 , 3.3199
11.156476 , 11.2213
2.0523376 , 2.0189
0.5504198 , 0.5179
3.4159698 , 3.3816
2.805893 , 2.8439
5.130946 , 4.9372
14.460643 , 14.4832
8.977946 , 8.8208
0.55745316 , 0.5991
5.530018 , 5.3461
0.0 , 0.1545
0.13698673 , 0.2084
2.5579166 , 2.5757
15.772954 , 15.7438
8.572149 , 8.7696
0.20219326 , 0.1001
2.901122 , 2.8105
2.0239792 , 1.9414
1.9650555 , 1.9314
0.5603342 , 0.6256
12.049408 , 11.8007
0.37761688 , 0.3242
5.937689 , 5.7881
0.34723282 , 0.2214
0.1913948 , 0.1335
0.4717493 , 0.4038
3.4915924 , 3.3316
1.5607185 , 1.452024
2.5193195 , 2.4934
18.882084 , 18.7775
0.0 , 0.2194
1.8102055 , 1.8942
0.69944 , 0.7067
0.25004578 , 0.1596
2.323802 , 2.2811
0.8262968 , 0.7996
0.18541336 , 0.2202
2.2444878 , 2.3404
5.172324 , 5.0878
0.47882462 , 0.5817
3.4082642 , 3.4205
0.4190836 , 0.1008
2.1109076 , 2.1477
18.38873 , 18.3614
7.3717527 , 7.3455
2.380849 , 2.3436
6.5719833 , 6.3783
1.8526459 , 1.7634
11.493638 , 11.6457
77.13003 , 77.731
9.953518 , 9.9496
2.3275528 , 2.3114
5.151355 , 4.9012
6.2032576 , 6.1306
13.863302 , 13.9025
14.487249 , 14.2078
3.2092724 , 3.1693
0.47415447 , 0.4126
0.085840225 , 0.1165
4.2168713 , 4.2883
2.028263 , 2.0056
1.9218473 , 1.9567
0.8401489 , 0.813
14.4991045 , 13.7433
3.3293133 , 3.2858
6.5838766 , 6.5855
0.24564171 , 0.3041
2.4716454 , 2.4895
4.5174932 , 4.2546
3.6766882 , 3.5146
18.552197 , 18.519
1.7148094 , 1.7798
3.4944172 , 3.5298
6.022869 , 6.0752
15.733292 , 15.9096
7.78207 , 7.9305
5.666033 , 5.5782
18.134117 , 18.1068
6.392188 , 6.2575
71.934906 , 71.9535
0.38594055 , 0.3552
2.7546692 , 2.6577
2.7048674 , 2.7607
5.8283863 , 5.8025
2.122532 , 2.1558
12.877327 , 13.1269
7.927703 , 7.5695
0.11170673 , 0.1339
0.41734695 , 0.1305
8.589077 , 8.1337
17.337456 , 18.4168
3.292574 , 3.18
2.1516037 , 2.1012
2.9551926 , 3.0017
4.676244 , 4.5184
5.976844 , 5.699
0.659503 , 0.7729
3.2552795 , 3.188
2.8249168 , 3.4554
15.769776 , 15.7189
0.33230114 , 0.128
8.937554 , 8.7753
13.538182 , 13.5289
2.3472462 , 2.3045
12.808821 , 13.1458
2.1769304 , 2.207
3.0666275 , 3.0291
4.9504805 , 4.7916
9.676958 , 9.6448
2.1274443 , 2.1182
0.23839188 , 0.1993
2.868246 , 2.9216
2.3403196 , 2.2898
2.1027699 , 2.065
8.501007 , 8.5312
6.1265764 , 6.5561
12.010873 , 12.0686
3.436862 , 3.4416
0.039152145 , 0.2183
2.7809763 , 2.7106
0.3895998 , 0.2893
3.9114885 , 3.5242
2.3213549 , 2.2892
3.2273521 , 3.2358
71.766045 , 71.9211
RMSE:  0.2277917050603062  MAPE: 0.10313894398916781
5: ground truth total-  339  predicted total -  339
100: ground truth total-  186  predicted total -  186
 more 100: ground truth total -  0  predicted total -  0



evaluating data from wilson d-slash kernel
1.1057396 , 0.367084
1.5593414 , 1.457218
1.7425346 , 2.54928
1.1072998 , 0.362631
1.4152946 , 0.52737
1.3321953 , 0.729948
1.6327019 , 1.814072
1.5108452 , 0.703684
0.42692184 , 0.045988
1.1067963 , 0.364837
1.7802315 , 1.582626
1.5598602 , 1.456398
1.3327179 , 0.726571
1.3324394 , 0.729025
1.0503464 , 0.193853
1.1059456 , 0.366018
1.6922226 , 2.185884
1.3335762 , 0.725021
0.4276085 , 0.045664
1.280613 , 0.351687
1.6967545 , 1.229525
1.3330727 , 0.727164
1.10643 , 0.364232
1.1061707 , 0.364531
1.58498 , 0.902826
0.42733002 , 0.045811
1.4654274 , 1.09287
1.4650726 , 1.094628
0.4279709 , 0.045643
0.3595848 , 0.025119
0.4284668 , 0.04563
1.332016 , 0.735312
1.4659462 , 1.088172
1.645546 , 1.054099
0.42711258 , 0.045928
RMSE:  0.5843051508241891  MAPE: 2.6869462065684266
