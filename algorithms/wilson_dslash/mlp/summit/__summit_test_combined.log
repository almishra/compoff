['Reduction', 'div_double', 'log_Outer', 'log_Inner', 'log_VarDecl', 'log_refExpr', 'log_intLiteral', 'log_floatLiteral', 'log_mem_to', 'log_mem_from', 'log_add_sub_int', 'log_add_sub_double', 'log_mul_int', 'log_mul_double', 'log_div_int', 'log_div_double', 'log_assign_int', 'log_assign_double', 'runtimes']
2640
19
<class 'numpy.dtype'> float64
2640
train batches:  119  validate samples: 211  test samples: 528
Epoch [0/150], Batch loss: 8.116
Epoch: 0 RMSE:  7.069328278513271  MAPE: 3.7377316190791823  L2+L1 loss: 4.116
Epoch [1/150], Batch loss: 3.529
Epoch: 1 RMSE:  7.792051610711929  MAPE: 2.036914193315102  L2+L1 loss: 4.683
Epoch [2/150], Batch loss: 3.494
Epoch: 2 RMSE:  4.171497449705089  MAPE: 1.9041318571738468  L2+L1 loss: 2.544
Epoch [3/150], Batch loss: 5.579
Epoch: 3 RMSE:  5.483562327859617  MAPE: 4.404435728112476  L2+L1 loss: 3.784
Epoch [4/150], Batch loss: 3.665
Epoch: 4 RMSE:  4.167673363979215  MAPE: 2.68265486990875  L2+L1 loss: 2.467
Epoch [5/150], Batch loss: 7.695
Epoch: 5 RMSE:  7.270058194969975  MAPE: 5.914599405892673  L2+L1 loss: 4.811
Epoch [6/150], Batch loss: 7.217
Epoch: 6 RMSE:  7.287935123249173  MAPE: 6.40891499777784  L2+L1 loss: 5.004
Epoch [7/150], Batch loss: 7.316
Epoch: 7 RMSE:  7.2761674636094735  MAPE: 6.180561781211328  L2+L1 loss: 4.91
Epoch [8/150], Batch loss: 7.272
Epoch: 8 RMSE:  7.292018678944175  MAPE: 6.468891209301113  L2+L1 loss: 5.028
Epoch [9/150], Batch loss: 7.263
Epoch: 9 RMSE:  7.337023901521229  MAPE: 6.93149171960542  L2+L1 loss: 5.234
Epoch [10/150], Batch loss: 8.588
Epoch: 10 RMSE:  7.282549572855129  MAPE: 6.318362161502243  L2+L1 loss: 4.968
Epoch [11/150], Batch loss: 7.229
Epoch: 11 RMSE:  7.290658486460326  MAPE: 6.44956435327056  L2+L1 loss: 5.02
Epoch [12/150], Batch loss: 7.275
Epoch: 12 RMSE:  7.303576715351565  MAPE: 6.614041858763935  L2+L1 loss: 5.09
Epoch [13/150], Batch loss: 7.313
Epoch: 13 RMSE:  7.298703652979167  MAPE: 6.556401360111042  L2+L1 loss: 5.065
Epoch [14/150], Batch loss: 7.262
Epoch: 14 RMSE:  7.29555725846647  MAPE: 6.516629304812253  L2+L1 loss: 5.049
Epoch [15/150], Batch loss: 7.156
Epoch: 15 RMSE:  7.290681040823993  MAPE: 6.449889864782482  L2+L1 loss: 5.02
Epoch [16/150], Batch loss: 10.569
Epoch: 16 RMSE:  17.99190895597558  MAPE: 17.07965725188419  L2+L1 loss: 13.808
Epoch [17/150], Batch loss: 7.859
Epoch: 17 RMSE:  7.307497781639636  MAPE: 6.6575335126513595  L2+L1 loss: 5.11
Epoch [18/150], Batch loss: 7.243
Epoch: 18 RMSE:  7.285309399636874  MAPE: 6.366743033186353  L2+L1 loss: 4.987
Epoch [19/150], Batch loss: 7.238
Epoch: 19 RMSE:  7.29755434037143  MAPE: 6.542135760898912  L2+L1 loss: 5.059
Epoch [20/150], Batch loss: 7.234
Epoch: 20 RMSE:  7.2970129926713065  MAPE: 6.535314599834601  L2+L1 loss: 5.056
Epoch [21/150], Batch loss: 7.232
Epoch: 21 RMSE:  7.369812394825299  MAPE: 7.172612311308887  L2+L1 loss: 5.349
Epoch [22/150], Batch loss: 7.309
Epoch: 22 RMSE:  7.317516711619859  MAPE: 6.7594145553906815  L2+L1 loss: 5.154
Epoch [23/150], Batch loss: 7.302
Epoch: 23 RMSE:  7.304512639659388  MAPE: 6.624641582143278  L2+L1 loss: 5.095
Epoch [24/150], Batch loss: 7.233
Epoch: 24 RMSE:  7.293347051626665  MAPE: 6.487223852233262  L2+L1 loss: 5.036
Epoch [25/150], Batch loss: 7.175
Epoch: 25 RMSE:  7.330269565957289  MAPE: 6.875071302661633  L2+L1 loss: 5.208
Epoch [26/150], Batch loss: 7.21
Epoch: 26 RMSE:  7.278595677692439  MAPE: 6.238738393352302  L2+L1 loss: 4.934
Epoch [27/150], Batch loss: 7.284
Epoch: 27 RMSE:  7.279304714403256  MAPE: 6.254169009992298  L2+L1 loss: 4.941
Epoch [28/150], Batch loss: 7.221
Epoch: 28 RMSE:  7.277393736305877  MAPE: 6.211082092294078  L2+L1 loss: 4.922
Epoch [29/150], Batch loss: 7.278
Epoch: 29 RMSE:  7.295334555773872  MAPE: 6.513724844017083  L2+L1 loss: 5.047
Epoch [30/150], Batch loss: 7.209
Epoch: 30 RMSE:  7.2955702638382185  MAPE: 6.516798532090565  L2+L1 loss: 5.049
Epoch [31/150], Batch loss: 7.226
Epoch: 31 RMSE:  7.296454522452557  MAPE: 6.528206533446135  L2+L1 loss: 5.053
Epoch [32/150], Batch loss: 7.207
Epoch: 32 RMSE:  7.296472107497248  MAPE: 6.5284314755514625  L2+L1 loss: 5.054
Epoch [33/150], Batch loss: 7.231
Epoch: 33 RMSE:  7.298059413301417  MAPE: 6.548440388239878  L2+L1 loss: 5.062
Epoch [34/150], Batch loss: 7.215
Epoch: 34 RMSE:  7.296150268143709  MAPE: 6.524302850659943  L2+L1 loss: 5.052
Epoch [35/150], Batch loss: 7.262
Epoch: 35 RMSE:  7.298057318282256  MAPE: 6.548414353273984  L2+L1 loss: 5.062
Epoch [36/150], Batch loss: 7.261
Epoch: 36 RMSE:  7.297834056888314  MAPE: 6.5456343396157886  L2+L1 loss: 5.061
Epoch [37/150], Batch loss: 4.52
Epoch: 37 RMSE:  1.4500715594777676  MAPE: 1.7032415408859893  L2+L1 loss: 1.155
Epoch [38/150], Batch loss: 1.249
Epoch: 38 RMSE:  1.052790297844057  MAPE: 0.8232847236935431  L2+L1 loss: 0.867
Epoch [39/150], Batch loss: 1.215
Epoch: 39 RMSE:  0.9679862358807146  MAPE: 0.5358423478040173  L2+L1 loss: 0.608
Epoch [40/150], Batch loss: 1.137
Epoch: 40 RMSE:  1.2994546981076331  MAPE: 0.6204405721469699  L2+L1 loss: 0.686
Epoch [41/150], Batch loss: 0.913
Epoch: 41 RMSE:  1.0191514495336702  MAPE: 0.4102440639949371  L2+L1 loss: 0.91
Epoch [42/150], Batch loss: 1.014
Epoch: 42 RMSE:  1.9805781383581063  MAPE: 1.4674842839729574  L2+L1 loss: 1.069
Epoch [43/150], Batch loss: 0.904
Epoch: 43 RMSE:  1.3589021971375888  MAPE: 0.33779075855528795  L2+L1 loss: 1.09
Epoch [44/150], Batch loss: 0.589
Epoch: 44 RMSE:  0.7316470339071889  MAPE: 0.20051235943926507  L2+L1 loss: 0.577
Epoch [45/150], Batch loss: 0.913
Epoch: 45 RMSE:  1.3429918624352117  MAPE: 1.3946961693718822  L2+L1 loss: 1.086
Epoch [46/150], Batch loss: 1.061
Epoch: 46 RMSE:  0.8766091415510943  MAPE: 0.6570490484570354  L2+L1 loss: 0.708
Epoch [47/150], Batch loss: 0.597
Epoch: 47 RMSE:  0.5431206072580925  MAPE: 0.4189187099162963  L2+L1 loss: 0.797
Epoch [48/150], Batch loss: 0.794
Epoch: 48 RMSE:  0.6478748502733316  MAPE: 0.4959318595940784  L2+L1 loss: 0.649
Epoch [49/150], Batch loss: 0.799
Epoch: 49 RMSE:  2.314782486239826  MAPE: 0.44581504205039774  L2+L1 loss: 0.838
Epoch [50/150], Batch loss: 0.862
Epoch: 50 RMSE:  0.4311115168035018  MAPE: 0.5531858261304357  L2+L1 loss: 0.537
Epoch [51/150], Batch loss: 0.662
Epoch: 51 RMSE:  1.0834156279331957  MAPE: 0.7849817865608044  L2+L1 loss: 0.751
Epoch [52/150], Batch loss: 0.976
Epoch: 52 RMSE:  2.9389270283633775  MAPE: 0.7323451458720401  L2+L1 loss: 1.559
Epoch [53/150], Batch loss: 0.917
Epoch: 53 RMSE:  0.6636369118740093  MAPE: 0.3689275359663065  L2+L1 loss: 0.527
Epoch [54/150], Batch loss: 0.644
Epoch: 54 RMSE:  0.9358313380729887  MAPE: 0.28409235558720725  L2+L1 loss: 0.451
Epoch [55/150], Batch loss: 0.792
Epoch: 55 RMSE:  0.38976506825400686  MAPE: 0.20208594789461062  L2+L1 loss: 0.404
Epoch [56/150], Batch loss: 0.847
Epoch: 56 RMSE:  1.2761602138966892  MAPE: 0.2586413232633686  L2+L1 loss: 0.842
Epoch [57/150], Batch loss: 1.147
Epoch: 57 RMSE:  0.5281913722270953  MAPE: 0.45820065139269883  L2+L1 loss: 0.462
Epoch [58/150], Batch loss: 0.616
Epoch: 58 RMSE:  0.8194523574852309  MAPE: 0.7811944210514884  L2+L1 loss: 0.643
Epoch [59/150], Batch loss: 0.818
Epoch: 59 RMSE:  0.6551984759470171  MAPE: 0.1409754551837144  L2+L1 loss: 0.441
Epoch [60/150], Batch loss: 0.332
Epoch: 60 RMSE:  0.39237331924530516  MAPE: 0.2558135963137041  L2+L1 loss: 0.365
Epoch [61/150], Batch loss: 0.331
Epoch: 61 RMSE:  0.3693881167729623  MAPE: 0.22018652481434436  L2+L1 loss: 0.382
Epoch [62/150], Batch loss: 0.314
Epoch: 62 RMSE:  0.5928380665541938  MAPE: 0.17600036469986186  L2+L1 loss: 0.368
Epoch [63/150], Batch loss: 0.325
Epoch: 63 RMSE:  0.4407549707196927  MAPE: 0.052880181500463405  L2+L1 loss: 0.329
Epoch [64/150], Batch loss: 0.312
Epoch: 64 RMSE:  0.7428431572327789  MAPE: 0.0632764816688469  L2+L1 loss: 0.451
Epoch [65/150], Batch loss: 0.29
Epoch: 65 RMSE:  0.3763840254634977  MAPE: 0.0942484363212677  L2+L1 loss: 0.33
Epoch [66/150], Batch loss: 0.306
Epoch: 66 RMSE:  0.431685662684752  MAPE: 0.12435691188727595  L2+L1 loss: 0.327
Epoch [67/150], Batch loss: 0.285
Epoch: 67 RMSE:  0.33319943394978846  MAPE: 0.13781715980666606  L2+L1 loss: 0.377
Epoch [68/150], Batch loss: 0.281
Epoch: 68 RMSE:  0.58183035112645  MAPE: 0.053609356611887544  L2+L1 loss: 0.397
Epoch [69/150], Batch loss: 0.297
Epoch: 69 RMSE:  0.5287121006178901  MAPE: 0.08894700847361778  L2+L1 loss: 0.335
Epoch [70/150], Batch loss: 0.304
Epoch: 70 RMSE:  0.2918240885244443  MAPE: 0.05524477944990214  L2+L1 loss: 0.317
Epoch [71/150], Batch loss: 0.27
Epoch: 71 RMSE:  0.23937247689129826  MAPE: 0.07181786761843026  L2+L1 loss: 0.316
Epoch [72/150], Batch loss: 0.29
Epoch: 72 RMSE:  0.22867902276802327  MAPE: 0.09352921458785807  L2+L1 loss: 0.332
Epoch [73/150], Batch loss: 0.302
Epoch: 73 RMSE:  0.3274864135465125  MAPE: 0.1861730707302877  L2+L1 loss: 0.399
Epoch [74/150], Batch loss: 0.308
Epoch: 74 RMSE:  0.37206479660498554  MAPE: 0.08804050298107756  L2+L1 loss: 0.347
Epoch [75/150], Batch loss: 0.302
Epoch: 75 RMSE:  0.2361802801355335  MAPE: 0.06598451469628627  L2+L1 loss: 0.321
Epoch [76/150], Batch loss: 0.303
Epoch: 76 RMSE:  0.5317706951315521  MAPE: 0.04823720775819282  L2+L1 loss: 0.375
Epoch [77/150], Batch loss: 0.307
Epoch: 77 RMSE:  0.2949319386793384  MAPE: 0.09203094253694971  L2+L1 loss: 0.317
Epoch [78/150], Batch loss: 0.305
Epoch: 78 RMSE:  0.3148876361469261  MAPE: 0.12488585128597168  L2+L1 loss: 0.338
Epoch [79/150], Batch loss: 0.267
Epoch: 79 RMSE:  0.35217083321049075  MAPE: 0.13773016309248926  L2+L1 loss: 0.328
Epoch [80/150], Batch loss: 0.284
Epoch: 80 RMSE:  0.22486336122890813  MAPE: 0.11760240054062335  L2+L1 loss: 0.323
Epoch [81/150], Batch loss: 0.266
Epoch: 81 RMSE:  0.35375201332515704  MAPE: 0.04000531295494519  L2+L1 loss: 0.375
Epoch [82/150], Batch loss: 0.336
Epoch: 82 RMSE:  0.18260810099665056  MAPE: 0.040544419841043816  L2+L1 loss: 0.304
Epoch [83/150], Batch loss: 0.279
Epoch: 83 RMSE:  0.4895626174879676  MAPE: 0.08348251788931456  L2+L1 loss: 0.325
Epoch [84/150], Batch loss: 0.237
Epoch: 84 RMSE:  0.18960652382067922  MAPE: 0.10644330586510163  L2+L1 loss: 0.307
Epoch [85/150], Batch loss: 0.29
Epoch: 85 RMSE:  0.48237981649828465  MAPE: 0.10548889256825515  L2+L1 loss: 0.337
Epoch [86/150], Batch loss: 0.266
Epoch: 86 RMSE:  0.7432818922439296  MAPE: 0.059410404081050784  L2+L1 loss: 0.371
Epoch [87/150], Batch loss: 0.292
Epoch: 87 RMSE:  0.33748214107405644  MAPE: 0.13382328104261507  L2+L1 loss: 0.326
Epoch [88/150], Batch loss: 0.285
Epoch: 88 RMSE:  0.31213765557805023  MAPE: 0.28962056534332753  L2+L1 loss: 0.402
Epoch [89/150], Batch loss: 0.267
Epoch: 89 RMSE:  0.17842897136367034  MAPE: 0.05369875569451205  L2+L1 loss: 0.308
Epoch [90/150], Batch loss: 0.23
Epoch: 90 RMSE:  0.23463932812244387  MAPE: 0.037981706416729155  L2+L1 loss: 0.299
Epoch [91/150], Batch loss: 0.217
Epoch: 91 RMSE:  0.25114089260514005  MAPE: 0.029895044317435823  L2+L1 loss: 0.298
Epoch [92/150], Batch loss: 0.221
Epoch: 92 RMSE:  0.26871129037706865  MAPE: 0.03605720188838883  L2+L1 loss: 0.3
Epoch [93/150], Batch loss: 0.222
Epoch: 93 RMSE:  0.2520182086456575  MAPE: 0.029965076132742477  L2+L1 loss: 0.3
Epoch [94/150], Batch loss: 0.226
Epoch: 94 RMSE:  0.257871636429951  MAPE: 0.028015355309275382  L2+L1 loss: 0.3
Epoch [95/150], Batch loss: 0.223
Epoch: 95 RMSE:  0.29684330737304104  MAPE: 0.04102795668528062  L2+L1 loss: 0.306
Epoch [96/150], Batch loss: 0.219
Epoch: 96 RMSE:  0.2892430776489841  MAPE: 0.03225132530934423  L2+L1 loss: 0.301
Epoch [97/150], Batch loss: 0.223
Epoch: 97 RMSE:  0.28397471617558323  MAPE: 0.02887337744955658  L2+L1 loss: 0.298
Epoch [98/150], Batch loss: 0.231
Epoch: 98 RMSE:  0.27514328917550146  MAPE: 0.04683683784875561  L2+L1 loss: 0.303
Epoch [99/150], Batch loss: 0.218
Epoch: 99 RMSE:  0.27769831262157846  MAPE: 0.02942947538404575  L2+L1 loss: 0.299
Epoch [100/150], Batch loss: 0.219
Epoch: 100 RMSE:  0.29055629142905887  MAPE: 0.03868689020462297  L2+L1 loss: 0.309
Epoch [101/150], Batch loss: 0.216
Epoch: 101 RMSE:  0.28716548159336325  MAPE: 0.03408333542362968  L2+L1 loss: 0.298
Epoch [102/150], Batch loss: 0.221
Epoch: 102 RMSE:  0.26107949413456316  MAPE: 0.03209603952099426  L2+L1 loss: 0.3
Epoch [103/150], Batch loss: 0.224
Epoch: 103 RMSE:  0.2545157568389638  MAPE: 0.029675408733154305  L2+L1 loss: 0.298
Epoch [104/150], Batch loss: 0.219
Epoch: 104 RMSE:  0.2854045511734535  MAPE: 0.04660010148171447  L2+L1 loss: 0.299
Epoch [105/150], Batch loss: 0.221
Epoch: 105 RMSE:  0.26918338003204323  MAPE: 0.03674000366120955  L2+L1 loss: 0.301
Epoch [106/150], Batch loss: 0.219
Epoch: 106 RMSE:  0.292133957950324  MAPE: 0.045504433198766805  L2+L1 loss: 0.302
Epoch [107/150], Batch loss: 0.226
Epoch: 107 RMSE:  0.2618945882427146  MAPE: 0.04239984797641795  L2+L1 loss: 0.307
Epoch [108/150], Batch loss: 0.219
Epoch: 108 RMSE:  0.28989205498878834  MAPE: 0.02999139895762663  L2+L1 loss: 0.296
Epoch [109/150], Batch loss: 0.221
Epoch: 109 RMSE:  0.28471447068996586  MAPE: 0.045310839238050626  L2+L1 loss: 0.304
Epoch [110/150], Batch loss: 0.223
Epoch: 110 RMSE:  0.28049386156185663  MAPE: 0.05412827422626353  L2+L1 loss: 0.3
Epoch [111/150], Batch loss: 0.217
Epoch: 111 RMSE:  0.30272997881815317  MAPE: 0.046701355425638295  L2+L1 loss: 0.303
Epoch [112/150], Batch loss: 0.221
Epoch: 112 RMSE:  0.28050994365177895  MAPE: 0.04043826501921291  L2+L1 loss: 0.3
Epoch [113/150], Batch loss: 0.222
Epoch: 113 RMSE:  0.29377514921849407  MAPE: 0.043684338996191514  L2+L1 loss: 0.313
Epoch [114/150], Batch loss: 0.217
Epoch: 114 RMSE:  0.2833281025867276  MAPE: 0.032121371835288265  L2+L1 loss: 0.299
Epoch [115/150], Batch loss: 0.218
Epoch: 115 RMSE:  0.3097832588726972  MAPE: 0.036145037240336936  L2+L1 loss: 0.302
Epoch [116/150], Batch loss: 0.22
Epoch: 116 RMSE:  0.2780328193448251  MAPE: 0.028518724282180243  L2+L1 loss: 0.299
Epoch [117/150], Batch loss: 0.218
Epoch: 117 RMSE:  0.24464757949816526  MAPE: 0.03088774661260644  L2+L1 loss: 0.3
Epoch [118/150], Batch loss: 0.217
Epoch: 118 RMSE:  0.25971984897497186  MAPE: 0.03148991620555432  L2+L1 loss: 0.3
Epoch [119/150], Batch loss: 0.22
Epoch: 119 RMSE:  0.2807433589416261  MAPE: 0.04545270002278083  L2+L1 loss: 0.3
Epoch [120/150], Batch loss: 0.215
Epoch: 120 RMSE:  0.2796116573596966  MAPE: 0.042352049354068035  L2+L1 loss: 0.3
Epoch [121/150], Batch loss: 0.215
Epoch: 121 RMSE:  0.2772306836332267  MAPE: 0.03894195489205749  L2+L1 loss: 0.3
Epoch [122/150], Batch loss: 0.216
Epoch: 122 RMSE:  0.2766101616026446  MAPE: 0.03533122604964076  L2+L1 loss: 0.299
Epoch [123/150], Batch loss: 0.213
Epoch: 123 RMSE:  0.2742355523124687  MAPE: 0.031991751009924026  L2+L1 loss: 0.298
Epoch [124/150], Batch loss: 0.212
Epoch: 124 RMSE:  0.2754575706085946  MAPE: 0.03163199520050853  L2+L1 loss: 0.299
Epoch [125/150], Batch loss: 0.215
Epoch: 125 RMSE:  0.27426926778314825  MAPE: 0.028487731517586455  L2+L1 loss: 0.298
Epoch [126/150], Batch loss: 0.215
Epoch: 126 RMSE:  0.2741934898441141  MAPE: 0.028112596626086228  L2+L1 loss: 0.298
Epoch [127/150], Batch loss: 0.214
Epoch: 127 RMSE:  0.2733744300757705  MAPE: 0.028202883219207827  L2+L1 loss: 0.299
Epoch [128/150], Batch loss: 0.21
Epoch: 128 RMSE:  0.27104250642407796  MAPE: 0.02698009375526872  L2+L1 loss: 0.298
Epoch [129/150], Batch loss: 0.214
Epoch: 129 RMSE:  0.27269925110749016  MAPE: 0.028065743541996237  L2+L1 loss: 0.299
Epoch [130/150], Batch loss: 0.213
Epoch: 130 RMSE:  0.27239935060711  MAPE: 0.026692549376254943  L2+L1 loss: 0.298
Epoch [131/150], Batch loss: 0.209
Epoch: 131 RMSE:  0.2732890089929994  MAPE: 0.027581938818495737  L2+L1 loss: 0.299
Epoch [132/150], Batch loss: 0.215
Epoch: 132 RMSE:  0.2724808328687948  MAPE: 0.028305362271484082  L2+L1 loss: 0.299
Epoch [133/150], Batch loss: 0.214
Epoch: 133 RMSE:  0.2727478012178712  MAPE: 0.028699288847975797  L2+L1 loss: 0.299
Epoch [134/150], Batch loss: 0.211
Epoch: 134 RMSE:  0.27276632284150376  MAPE: 0.02715388862153397  L2+L1 loss: 0.298
Epoch [135/150], Batch loss: 0.215
Epoch: 135 RMSE:  0.2725524645036166  MAPE: 0.02720747883968565  L2+L1 loss: 0.298
Epoch [136/150], Batch loss: 0.215
Epoch: 136 RMSE:  0.27261065812532287  MAPE: 0.0279125630749374  L2+L1 loss: 0.299
Epoch [137/150], Batch loss: 0.217
Epoch: 137 RMSE:  0.27502388602639877  MAPE: 0.028828597066752597  L2+L1 loss: 0.299
Epoch [138/150], Batch loss: 0.215
Epoch: 138 RMSE:  0.2720923900739319  MAPE: 0.02696009913007016  L2+L1 loss: 0.298
Epoch [139/150], Batch loss: 0.214
Epoch: 139 RMSE:  0.27346250756902957  MAPE: 0.028143875612553063  L2+L1 loss: 0.299
Epoch [140/150], Batch loss: 0.213
Epoch: 140 RMSE:  0.27123378059919817  MAPE: 0.02932722915939204  L2+L1 loss: 0.3
Epoch [141/150], Batch loss: 0.216
Epoch: 141 RMSE:  0.27159115331077155  MAPE: 0.028295678627401812  L2+L1 loss: 0.299
Epoch [142/150], Batch loss: 0.215
Epoch: 142 RMSE:  0.27299042126738216  MAPE: 0.028803087549842864  L2+L1 loss: 0.299
Epoch [143/150], Batch loss: 0.209
Epoch: 143 RMSE:  0.2709609444808153  MAPE: 0.028677250161588737  L2+L1 loss: 0.299
Epoch [144/150], Batch loss: 0.213
Epoch: 144 RMSE:  0.272339224409105  MAPE: 0.02831636728941804  L2+L1 loss: 0.298
Epoch [145/150], Batch loss: 0.214
Epoch: 145 RMSE:  0.2699251231799402  MAPE: 0.030133306410510485  L2+L1 loss: 0.3
Epoch [146/150], Batch loss: 0.207
Epoch: 146 RMSE:  0.2754103091356622  MAPE: 0.028895829740907937  L2+L1 loss: 0.299
Epoch [147/150], Batch loss: 0.214
Epoch: 147 RMSE:  0.2733557612885948  MAPE: 0.028842782824740832  L2+L1 loss: 0.299
Epoch [148/150], Batch loss: 0.214
Epoch: 148 RMSE:  0.27612375020144436  MAPE: 0.030397357374278674  L2+L1 loss: 0.3
Epoch [149/150], Batch loss: 0.215
Epoch: 149 RMSE:  0.2734693831230985  MAPE: 0.03002444276936726  L2+L1 loss: 0.299


Evaluating Model.......
Best Model - RMSE: inf  MAPE: inf  L2+L1- inf
predicted_runtime, ground_truth
11.961868 , 11.8496
4.5919895 , 4.4515
16.254381 , 16.1852
5.096445 , 5.2192
19.101013 , 19.1057
5.546877 , 5.4056
8.909206 , 8.8667
8.343891 , 8.3385
0.46558285 , 0.4795
0.47182512 , 0.4369
22.413763 , 23.2006
11.438119 , 11.3935
0.14440918 , 0.1305
3.860163 , 3.7981
0.61191607 , 0.6287
0.62497616 , 0.6091
18.447477 , 18.3216
1.2503476 , 1.1657
11.220754 , 11.2364
0.2326932 , 0.2192
0.49471283 , 0.5056
15.279177 , 15.42
0.3727193 , 0.3844
2.4335086 , 2.505
2.4744189 , 2.4316
0.22481298 , 0.2182
2.355768 , 2.4336
0.54521036 , 0.5243
0.3835392 , 0.3682
12.304094 , 12.154
3.6495147 , 3.6592
19.61033 , 19.2693
6.566478 , 6.5418
8.441345 , 8.4535
1.0052247 , 0.9884
12.376425 , 12.6297
9.044786 , 8.6357
3.123667 , 3.0167
3.354377 , 3.268
5.584346 , 5.6623
3.7116745 , 3.6655
21.623962 , 21.206
11.507998 , 11.5124
2.880202 , 2.8289
3.950079 , 3.8633
1.917727 , 1.9757
17.209713 , 17.1785
2.5715854 , 2.66
0.18807173 , 0.1738
0.6227379 , 0.6192
3.5394132 , 3.5841
5.7517085 , 5.8657
0.84622955 , 0.8144
11.920879 , 11.9334
3.6223023 , 3.6238
18.599794 , 18.1028
3.6932044 , 3.5697
0.54218864 , 0.5165
0.54131603 , 0.5244
22.57027 , 22.9369
3.6030738 , 3.5266
4.9297924 , 4.9634
0.21752787 , 0.2208
6.730396 , 6.8185
4.730875 , 4.6444
0.55920506 , 0.5234
7.9817815 , 8.2817
11.930746 , 12.2141
2.2112494 , 2.1545
0.1585536 , 0.1464
0.9692826 , 0.9342
21.536905 , 21.2936
6.3813944 , 6.4707
0.26602364 , 0.2401
0.3919015 , 0.3701
0.5647054 , 0.5413
2.549438 , 2.5383
1.3466144 , 1.1682
3.565065 , 3.5052
5.0771317 , 5.1752
5.317642 , 5.1622
4.0883236 , 4.2154
7.4991384 , 7.3009
10.594078 , 10.6926
5.697216 , 5.6559
15.541389 , 16.0307
15.309826 , 15.1789
2.6192508 , 2.53
0.55806684 , 0.5333
0.17394161 , 0.1521
21.70412 , 21.3573
0.994329 , 0.9831
2.5015025 , 2.4742
5.1044836 , 5.0315
1.2875443 , 1.1809
0.70205545 , 0.716
0.67438793 , 0.6803
3.5613291 , 3.4598
5.029339 , 5.1777
11.308245 , 11.1572
2.8960443 , 2.822
0.15098858 , 0.144
5.2591553 , 5.1978
6.1244287 , 6.0254
8.592142 , 8.5151
10.820219 , 10.9645
3.2281172 , 3.1499
7.16838 , 7.0707
3.353943 , 3.3534
2.6695187 , 2.7224
0.36816454 , 0.4002
4.9194403 , 5.0468
0.4467473 , 0.415
0.23515558 , 0.2905
9.152435 , 9.5758
13.055103 , 12.9686
10.031277 , 10.408
3.9217758 , 4.0001
6.1610403 , 6.1549
3.1689515 , 3.1894
3.5989606 , 3.6279
0.27799463 , 0.2651
18.542248 , 18.0593
0.7142687 , 0.7297
5.3671913 , 5.2846
6.1279807 , 6.0382
0.20466089 , 0.1841
13.112488 , 13.0739
3.4707391 , 3.362
7.8759804 , 7.6502
0.30923414 , 0.2672
4.336662 , 4.2613
13.064372 , 12.8513
6.294441 , 6.1625
0.37203312 , 0.3495
7.267748 , 7.309
4.139192 , 4.1929
6.2127805 , 6.2828
1.9212756 , 1.9828
15.925346 , 16.0686
5.030498 , 4.9112
6.4591236 , 6.431
2.0991817 , 2.1141
0.6903701 , 0.7294
0.32050943 , 0.3096
3.0030417 , 3.0368
10.201075 , 10.4263
6.1025505 , 6.1067
10.182417 , 10.1499
0.235219 , 0.2183
1.1230073 , 1.0767
11.296846 , 11.2503
2.585463 , 2.7154
8.8278265 , 9.0816
2.0691986 , 2.0403
4.0904818 , 4.2036
13.363274 , 13.3784
0.49287415 , 0.5277
5.25704 , 5.1378
2.3146 , 2.3946
4.316409 , 4.5253
0.2565055 , 0.2529
0.69191504 , 0.7174
3.0229905 , 3.1689
0.6826911 , 0.6943
3.8028164 , 3.8344
2.8315363 , 2.7373
2.1229482 , 2.0044
2.6865318 , 2.7153
6.0622144 , 5.9052
0.058032513 , 0.052868
26.038408 , 26.5771
4.6804724 , 4.5742
3.3818777 , 3.3112
2.784432 , 2.7972
2.6209867 , 2.5736
0.60992384 , 0.6082
4.094382 , 4.0647
2.8384402 , 2.7539
3.283319 , 3.274
3.1457658 , 3.1514
4.7699137 , 4.6655
0.23777533 , 0.2247
0.25439405 , 0.2406
1.9221673 , 1.9087
15.461109 , 15.5263
2.380653 , 2.5433
0.13507128 , 0.119
6.2228413 , 6.3437
5.9056053 , 5.9943
14.677204 , 15.0364
3.0326135 , 3.0397
4.6287584 , 4.6037
3.823707 , 3.912
13.804859 , 14.1494
7.285079 , 7.2083
0.14140081 , 0.1211
3.287635 , 3.3977
5.8248963 , 5.7974
3.5407174 , 3.575
19.021425 , 19.7591
0.2042098 , 0.2328
4.9837694 , 4.9807
4.240176 , 4.2061
2.457491 , 2.4224
19.321465 , 19.0044
3.2154422 , 3.1783
6.671119 , 6.5968
3.2304602 , 3.2997
19.102428 , 19.2525
1.9292135 , 1.8943
0.2878785 , 0.2886
0.37539434 , 0.3763
13.002353 , 12.9819
19.859638 , 19.9554
1.3478613 , 1.3439
3.1507201 , 3.16
19.070526 , 19.0082
3.316355 , 3.345
4.072428 , 4.2058
0.72312784 , 0.711
0.9909611 , 0.9157
11.734137 , 11.7855
0.92618704 , 0.9204
0.65569973 , 0.6787
2.722897 , 2.6569
19.455835 , 19.2899
4.8774624 , 5.0185
15.49975 , 16.0423
13.23789 , 12.9018
4.7122393 , 4.7956
0.8311677 , 0.8455
3.5662873 , 3.4977
0.56287193 , 0.5311
2.5562193 , 2.5222
4.7462416 , 4.6414
3.598757 , 3.7352
0.19714689 , 0.1806
0.25449944 , 0.2418
9.764601 , 9.7091
3.2793772 , 3.1826
3.709738 , 3.6962
3.1501446 , 3.164
0.47862196 , 0.4441
3.7179377 , 3.6486
5.060475 , 4.9323
9.8672905 , 9.7129
4.5601597 , 4.496
3.3794827 , 3.3208
4.3523617 , 4.2943
5.490783 , 5.4377
0.53487396 , 0.5224
0.7307577 , 0.7377
0.47550726 , 0.4865
10.158492 , 10.2207
2.5829232 , 2.6563
4.916483 , 4.8991
0.7403846 , 0.7162
4.958791 , 4.8737
3.281551 , 3.2018
1.0084128 , 0.944
3.6546538 , 3.7692
18.813162 , 18.3939
18.423067 , 18.3329
0.19911432 , 0.1755
4.731187 , 4.7118
11.568266 , 11.6834
0.5039258 , 0.6573
7.2504387 , 7.2764
15.949116 , 15.8722
2.2090678 , 2.1005
4.6116695 , 4.6243
16.19366 , 16.2667
5.1589127 , 5.0936
3.3807907 , 3.3631
15.757542 , 16.0304
0.16846752 , 0.1656
4.4264917 , 4.3472
4.935444 , 4.7945
8.236438 , 8.6979
85.24697 , 84.5683
9.365796 , 9.4923
10.026306 , 9.6974
0.17135668 , 0.1444
1.6553745 , 1.6317
0.3676653 , 0.3621
6.42861 , 6.6388
29.739012 , 30.0664
11.384619 , 11.335
5.3664794 , 5.4274
5.8916845 , 5.7327
3.2322981 , 3.2552
0.8586564 , 0.8102
4.7444386 , 4.7215
0.8339381 , 0.8665
0.1563859 , 0.1374
14.642836 , 14.9673
5.3003106 , 5.2495
4.932628 , 4.9572
10.184382 , 10.3248
9.171684 , 8.9076
0.09631586 , 0.1639
5.181068 , 5.0443
6.630437 , 6.7724
1.123137 , 1.0519
5.6575227 , 5.6094
2.693081 , 2.7453
14.310762 , 14.12
11.006079 , 11.1465
3.3833575 , 3.2914
2.2003474 , 2.1907
89.35441 , 90.9927
12.3454685 , 12.6972
0.31721497 , 0.306
2.5429199 , 2.5279
8.727299 , 8.857
7.80363 , 7.8237
1.1323724 , 1.1206
0.12987185 , 0.1285
4.6540046 , 4.7801
5.588937 , 5.7354
14.332239 , 14.5239
5.303997 , 5.1871
2.4356887 , 2.4928
10.477703 , 10.4786
0.8194275 , 0.8097
0.16849947 , 0.1743
0.24918032 , 0.2398
11.28647 , 11.3
9.822899 , 9.6768
6.6250844 , 6.7624
5.592598 , 5.4664
10.844242 , 11.135
77.80122 , 72.9363
0.69203997 , 0.7112
5.744288 , 5.7139
4.310845 , 4.362
0.13531351 , 0.1218
12.347204 , 12.1174
8.965692 , 9.0023
12.063715 , 12.2349
3.2455769 , 3.1944
3.655317 , 3.5622
7.321229 , 7.3109
0.3470168 , 0.3666
0.66298676 , 0.7026
3.4695938 , 3.4099
0.3286395 , 0.3066
0.14784145 , 0.1357
3.742246 , 3.7957
0.14376783 , 0.1214
4.347621 , 4.3301
5.579943 , 5.7117
3.3285494 , 3.2304
3.4568486 , 3.4641
5.035384 , 4.9194
2.9219844 , 2.8675
26.24375 , 25.6411
1.3278942 , 1.1778
5.3452115 , 5.1805
0.28190374 , 0.2428
21.498299 , 21.5273
0.27216673 , 0.2673
3.9104142 , 3.9509
3.2811494 , 3.152
9.16757 , 9.4242
4.4520583 , 4.5333
3.8607657 , 3.7123
2.8747318 , 2.8555
0.20249891 , 0.1859
2.9244053 , 2.808
3.5656927 , 3.4987
5.7361517 , 5.88
5.2903147 , 5.3815
22.751091 , 22.7606
8.918085 , 8.7271
15.215746 , 15.2517
8.371521 , 8.023
7.2514334 , 7.4011
4.002094 , 4.202
4.333488 , 4.1966
0.6235819 , 0.6219
19.217512 , 19.0736
5.6020885 , 5.7788
4.323685 , 4.2094
2.2369037 , 2.3114
19.0497 , 19.6737
0.2493558 , 0.2211
4.3308263 , 4.2478
5.4135947 , 5.2272
0.548738 , 0.5407
10.11216 , 10.1315
10.69479 , 11.1351
16.735884 , 17.1649
16.357212 , 16.3007
16.134933 , 16.0929
4.4368305 , 4.5584
2.296591 , 2.2121
12.229148 , 12.4124
9.825718 , 9.8669
0.29707575 , 0.3696
0.17534399 , 0.1615
4.845005 , 4.8294
2.0155392 , 2.0139
4.2999783 , 4.2649
0.12552261 , 0.1402
6.3548713 , 6.5391
0.964375 , 0.9928
22.716787 , 22.6611
2.8949087 , 2.9707
18.390644 , 18.3367
0.47055864 , 0.4682
3.5054986 , 3.4814
4.366251 , 4.3122
4.939951 , 4.8128
4.94483 , 4.8169
0.50694513 , 0.4736
2.8473084 , 2.9454
8.841657 , 9.015
0.3281293 , 0.175775
4.9936337 , 4.8376
4.002019 , 4.0931
0.25905943 , 0.3154
4.1129117 , 4.0399
2.8145404 , 2.8246
2.897577 , 2.9316
10.618837 , 10.4015
4.2813377 , 4.3347
2.2966719 , 2.3626
4.8647714 , 4.9675
3.5921888 , 3.5396
2.299644 , 2.2787
3.472869 , 3.4226
2.333117 , 2.4002
0.20782137 , 0.2401
7.239921 , 7.2886
3.005644 , 3.0141
9.61188 , 9.5857
3.23465 , 3.2968
4.5595155 , 4.4382
4.1638193 , 4.1052
3.9271648 , 4.0129
16.010954 , 15.6633
1.7124262 , 1.6215
19.770731 , 19.9697
2.366373 , 2.343
2.3880565 , 2.3733
10.635969 , 10.842
7.809253 , 7.7547
12.193193 , 11.9963
3.3425999 , 3.2629
12.238405 , 12.0747
0.6061826 , 0.6419
2.8769922 , 2.9714
13.102674 , 13.1936
4.7429037 , 4.8401
21.60055 , 21.3794
0.9693303 , 0.9429
5.4074306 , 5.4964
0.5998807 , 0.6021
4.3235164 , 4.2834
1.826467 , 1.8438
0.6952543 , 0.8419
0.55229425 , 0.5249
3.5884545 , 3.5334
9.2368555 , 9.1948
8.482547 , 8.7441
0.18084192 , 0.1735
6.5080757 , 6.3861
8.599523 , 8.4975
4.767393 , 4.8464
0.2151866 , 0.2177
11.433706 , 11.357
4.965883 , 4.8708
7.6825256 , 7.618
0.37065363 , 0.4221
0.14173174 , 0.1153
5.636095 , 5.7727
16.664253 , 17.3501
0.15077114 , 0.142
6.1176844 , 6.0929
6.6707306 , 6.5267
5.9215283 , 5.9396
5.902631 , 5.872
8.99642 , 8.8571
4.9305615 , 4.8679
19.532364 , 19.4309
3.0708141 , 3.0893
0.27220297 , 0.2684
6.1415367 , 6.1443
0.2764578 , 0.2778
9.808872 , 9.599
0.3503008 , 0.377471
0.941391 , 0.949
5.9094515 , 6.0003
1.1283154 , 1.0993
9.702452 , 9.7345
19.819824 , 20.3335
19.389845 , 19.3427
3.5419214 , 3.53
11.297846 , 11.3928
9.970621 , 9.6952
3.6436243 , 3.5271
6.1434097 , 6.1092
0.36931372 , 0.3556
7.285783 , 7.4493
5.6477532 , 5.9985
4.344341 , 4.4059
3.1664014 , 3.1038
0.9358077 , 1.0102
19.43742 , 19.205
0.16432142 , 0.1485
2.3727002 , 2.4382
17.046783 , 17.1418
0.1943698 , 0.2233
9.307074 , 9.5417
4.463662 , 4.3672
11.611807 , 11.5969
4.3129296 , 4.3996
4.3226056 , 4.3722
4.447213 , 4.5436
4.8806095 , 4.7546
7.6409817 , 7.709
16.160757 , 16.1922
19.79983 , 20.4185
0.27791548 , 0.2389
3.82532 , 3.7858
13.2713375 , 13.1105
RMSE:  0.2704165875427641  MAPE: 0.03146567285019315
5: ground truth total-  316  predicted total -  316
100: ground truth total-  212  predicted total -  212
 more 100: ground truth total -  0  predicted total -  0



evaluating data from wilson d-slash kernel
0.70070314 , 0.725926
1.6131692 , 1.837392
1.9602561 , 1.228696
0.6667757 , 0.352462
1.0638165 , 1.094004
0.7037983 , 0.734373
0.69865274 , 0.729243
1.3430481 , 0.701665
0.062084675 , 0.045938
1.3805037 , 1.500917
1.3739305 , 1.454762
1.0328164 , 0.526036
0.68590164 , 0.731523
1.8184867 , 2.177076
0.70238113 , 0.731757
1.071567 , 1.124107
1.5794458 , 0.87707
1.6244087 , 1.827261
2.0069122 , 2.559
0.063473225 , 0.045991
0.06400108 , 0.04637
0.69227743 , 0.724201
1.9952488 , 2.552167
1.3656259 , 1.463917
1.8301253 , 2.172812
0.06284952 , 0.053237
1.784091 , 1.052783
0.69600725 , 0.724274
1.0683508 , 1.090271
1.0560656 , 1.089387
RMSE:  0.3330122541047363  MAPE: 0.2591280377603202
